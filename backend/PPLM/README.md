# PPLM
+ reference: Plug and Play Language Model

# Model
+ GPT2 Language Model
+ one-layer MLP for Text Classification

# Example
+ Prompt: ‘today is an interesting day’, the origin GPT2 generate outputs “Today is an interesting day for science, because today is the day that we learn about what it is we’re doing, what it’s like to be….”. And the personalized text output with a given label of “Lisa Simpson” is “Today is an interesting day, because we’re all getting one of those old Pixar cartoons! We’re so glad to see that film-maker Walt, …”.
+ Prompt: “Don't be evil and do the right thing.”, GPT2 outputs “Don't be evil and do the right thing. This week I'm going to take you up on it.” while the personalized text output of “Grandpa Simpson” is “Don't be evil and do the right thing, your children will. It's your responsibility to teach your to take them.” 
